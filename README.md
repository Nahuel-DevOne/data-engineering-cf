<section id="inicio" align="center">
  <h1>Proyecto final</h1>
  <h2>Ingesta de datos de ligas de f√∫tbol</h2>
  <img src="./img/img-bootcamp-ing-datos.png"/>
</section>

<h3>Proyecto para el Bootcamp de Ingenier√≠a de datos en <a href="https://codigofacilito.com">C√≥digo Facilito</a></h3>

<h3>L√≠der del bootcamp: <a href="https://talkingpts.org/our-team/sergio-sanchez/">Sergio S√°nchez, Ingeniero de Datos Sr. en TalkingPoints</a></h3>

<h3>Tabla de Contenidos:</h3>

- [**Informaci√≥n del proyecto**](#informaci√≥n-del-proyecto) üìÅ
- [**Version 1.0.0:**](#version-100) ‚úÖ
- [**Fuentes de datos**](#fuentes-de-datos) üóÑÔ∏è
- [**Prerrequisitos**](#prerrequisitos) üìù
- [**Herramientas y tecnolog√≠as**](#herramientas-y-tecnolog√≠as) üõ†Ô∏è
- [**Instalaci√≥n y configuraci√≥n del Entorno**](#instalaci√≥n-y-configuraci√≥n-del-entorno) üíª
- [**Documentaci√≥n T√©cnica**](#documentaci√≥n-t√©cnica) ‚öôÔ∏è
- [**Screenshots**](#screenshots) üì∏
- [**Informaci√≥n adicional**](#informaci√≥n-adicional) ü™ß
- [**Agradecimientos**](#agradecimientos) üëãüèΩ
- [**Autor**](#autor) ‚ö°ü™™

### **Informaci√≥n del proyecto**

Proyecto final para el bootcamp de Ingenier√≠a de Datos de [C√≥digo Facilito](https://codigofacilito.com), donde se va a construir un sistema de ETL para ingestar datos de distintas ligas de f√∫tbol de Europa, aplicando lo aprendido durante la cursada y utilizando varias de las herramientas vistas en el curso.

- Objetivo General:
  
  Construir un sistema de ETL donde se ingesta en una tabla de Snowflake la informaci√≥n de las 7 ligas de f√∫tbol m√°s importantes de Europa

- Requisitos Espec√≠ficos:
  - Extraer datos de m√∫ltiples fuentes (p√°ginas web) con python.
  - Transformar estos datos con Python para obtener un dataset limpio.
  - Crear un DAG en Airflow, desplegado de manera local con Astro CLI, para que dos veces por semana vaya a la p√°gina web, extraiga la informaci√≥n, la transforme, y luego se cargue en una tabla en Snowflake.
  - Una vez hecho esto, se podr√° hacer todo tipo de trabajos de anal√≠tica de datos, ya sea top five de los equipos con m√°s goles, con menos goles, con mayor partidos ganados, etc.

- Alcance:
  
  Para el p√∫blico en general, no se busca resolver una problem√°tica en particular, sino practicar algunas de las herramientas vistas en el bootcamp y mostrar un ETL sencillo que capture la esencia de un proceso b√°sico y fundamental en Ingenier√≠a de datos, mostrando el paso a paso de la extracci√≥n, la transformaci√≥n y la carga de distintas ligas de Europa, con actualizaci√≥n autom√°tica peri√≥dica.


### **Version 1.0.0:**

[![Demo](https://img.shields.io/badge/Demo_(En_proceso)-informational?style=for-the-badge&logo=vercel&logoColor=fff&color=23272d)](https://...)

### **Fuentes de datos**

- df_ligas.csv
- team_table.csv

### **Prerrequisitos**

Lista de software y herramientas, que necesitas para instalar y ejecutar este proyecto:

- Git
- GitHub
- Docker
- Python 3.2 en adelante
- Pandas
- Snowflake
- Airflow
- Astro CLI

### **Herramientas y tecnolog√≠as**

Tecnolog√≠as utilizadas para construir el proyecto:

- [Git](https://git-scm.com/) - El controlador de versiones utilizado
- [GitHub](https://github.com/) - La plataforma de desarrollo colaborativo, donde se aloja este proyecto.
- [Docker](https://www.docker.com/) - La tecnolog√≠a de contenedores utilizada para manejar una imagen de airflow.
- [Python](https://www.python.org/) - El lenguaje de programaci√≥n utilizado.
- [Pandas](https://pandas.pydata.org/) - Una librer√≠a  de Python para la manipulaci√≥n y el an√°lisis de los datos.
- [SQL](https://www.postgresql.org) - El lenguaje de consulta utilizado para bases de datos relacionales.
- [Snowflake](https://www.snowflake.com/es/) - La plataforma de almacenamiento de datos basada en la nube que fue utilizada. 
- [Airflow](https://airflow.apache.org/) - La plataforma de gesti√≥n de flujo (un orquestador) utilizada.
- [Astronomer](https://docs.astronomer.io/) - Aplicaci√≥n de software como servicio (SaaS) que posee y ejecuta recursos de Astro. En este caso se utiliza Astro CLI para desplegar y correr la UI de Airflow.

### **Instalaci√≥n y configuraci√≥n del Entorno** 

Una gu√≠a paso a paso sobre c√≥mo configurar el entorno de desarrollo e instalar todas las dependencias.

`Astro CLI`

```bash
# Instalar Astro CLI por medio de WSL
curl -sSL install.astronomer.io | sudo bash -s

# En el Visual Studio Code o el editor de tu preferencia, inicializar Astro y todos los paquetes necesarios
astro dev init

# Levantar la UI de Airflow
astro dev start o bien sudo astro dev start en caso de acceso denegado  
```



`Docker`

```bash
# paso 1
```

`Snowflake`

```python
# paso 2
```


`Snowflake`
Crear una cuenta y un nuevo warehouse.
Establecer roles y permisos para el acceso seguro.
Documentar el proceso de configuraci√≥n para futuras referencias.

`DBT`
Instalar DBT localmente o usar DBT Cloud.
Configurar el perfil de DBT para conectar con Snowflake.
Crear un proyecto DBT inicial.

`Python`
Configurar un entorno virtual.
Instalar bibliotecas necesarias (requests, pandas, snowflake-connector-python).
Configurar herramientas de desarrollo (IDE, control de versiones).

`Dise√±o del Modelo de Datos`
Esquema de Snowflake:
Definir tablas para ventas, clientes, y datos de marketing.
Documentar el esquema y las relaciones entre tablas.

`Modelos de DBT`
Crear modelos de transformaci√≥n.
Definir c√≥mo las tablas ser√°n transformadas (agregaciones, joins, limpieza de datos).
Documentar cada modelo con descripciones en el c√≥digo.

`Extracci√≥n de Datos`
Scripts de Python:
Escribir scripts para extraer datos de APIs o bases de datos.
Utilizar pandas para manipular datos si es necesario.
Automatizar la extracci√≥n de datos mediante cron jobs o Airflow.
Documentar los scripts, incluyendo par√°metros, formatos de datos y frecuencia de extracci√≥n.
 
`Carga de Datos`
Carga inicial a Snowflake:
Usar snowflake-connector-python para cargar datos.
Crear tablas en Snowflake usando scripts SQL o desde Python.
Documentar el proceso de carga, incluyendo mapeo de datos y configuraci√≥n de carga.

`Transformaci√≥n de Datos`
DBT para transformaci√≥n:
Configurar y ejecutar modelos DBT.
Utilizar pruebas DBT para asegurar la calidad de los datos.
Documentar transformaciones, incluyendo l√≥gica de negocio y optimizaciones.

`An√°lisis y Reporting`
SQL y Herramientas de BI:
Crear consultas SQL para an√°lisis.
Configurar dashboards en herramientas de BI conectadas a Snowflake.
Documentar consultas y dashboards, incluyendo KPIs y m√©tricas visualizadas.

---

### **Documentaci√≥n T√©cnica**


`Procesos`

1. Ingesta
   
   - dfafaf
   - fdasf
   - dfafa
   - dfafadf
   - dfafafd
   - dfafd
   - 
   
2. Carga
    
   - dfafaf
   - dfadf
   - dfadfa
   - dfdfaf
   - dfadf
 
3. Transformaci√≥n

   - dfafaf
   - dfadf
   - dfadfa
   - dfdfaf
   - dfadf


---
### **Screenshots**




### **Informaci√≥n adicional**




### **Agradecimientos**

- En especial, agradecimiento a C√≥digo Facilito por la excelente experiencia del bootcamp, la entrega y el compromiso permanente con toda su comunidad, que se extiende m√°s all√° del √°mbito acad√©mico y son un ejemplo de plataforma educativa a nivel internacional.
- Agradecimientos al l√≠der del bootcamp Sergio S√°nchez por dise√±ar los contenidos, y a todos los profesores y el equipo que conforman C√≥digo facilito, brindando su apoyo y conocimiento para lograr la mejor experiencia educativa.


---

### **Autor**

<p align="center">
  <a href="https://git.io/typing-svg"><img src="https://readme-typing-svg.demolab.com?font=Fira+Code&weight=500&size=21&pause=1000&color=C2D9F8&width=435&lines=Hello+World!+I+am+Nahuel;A+passionate+Data+Engineer;and+Full+Stack+Developer‚ö°." alt="Typing SVG" /></a>
</p>

<h3>¬°Hola, mi nombre es <b>Nahuel</b> üëãüèΩ!</h3>

- Soy de Buenos Aires (Argentina).
- Estudio Ingenier√≠a en sistemas.
- Me gusta leer y estudiar sobre diversos temas, explorar nuevas tecnolog√≠as y resolver problemas.
- Me desempe√±o como Data Engineer en NTT Data, pero en mi trabajo diario hago tanto ingenier√≠a de datos como ciencia de datos y machine learning.
- Tengo formaci√≥n en desarrollo full Stack con JavaScript y Python, pero por mi trabajo utilizo diariamente tecnolog√≠as para data como Python, numpy, pandas, Scikit learn, SQL, tecnolog√≠as de Big Data como PySpark y Microsoft Azure para trabajar en la nube, entre otras.

üí¨ Si√©ntete libre de ponerte en contacto conmigo.

[![Contact Me](https://img.shields.io/badge/Gmail-informational?style=for-the-badge&logo=Mail.Ru&logoColor=fff&color=c6362c)](mailto:nahue.developer1@gmail.com)
[![LinkedId](https://img.shields.io/badge/LinkedIn-informational?style=for-the-badge&logo=linkedin&logoColor=fff&color=0274b3)](https://www.linkedin.com/in/nahuel-developer/)
[![GitHub Profile](https://img.shields.io/badge/GitHub-informational?style=for-the-badge&logo=GitHub&logoColor=fff&color=343941)](https://github.com/Nahuel-DevOne)
[![Linktree](https://img.shields.io/badge/-Linktree-323330?style=for-the-badge&logo=linktree&logoColor=#41e45f)](https://linktr.ee/nahuel.lopez)

Desarrollado con üíô por [**Nahuel DevOne‚ö°**](https://linktr.ee/nahuel.lopez)

[**‚ö°Volver al inicio‚ö°**](#inicio)

---